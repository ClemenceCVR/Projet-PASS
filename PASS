def calcule_coefficient_zipf(nb):
    # On importe les bibliothèques nécessaires
    import requests
    from bs4 import BeautifulSoup
    import numpy as np

    # On scrape les informations des villes des États-Unis sur Wikipedia
    url = "https://en.wikipedia.org/wiki/List_of_metropolitan_statistical_areas"
    reponse = requests.get(url)
    soup = BeautifulSoup(reponse.content, 'html.parser')
    tableau = soup.find_all('table')[1]
    rows = tableau.find_all('tr')[1:]

    # On extrait le nom et la population de chaque zone métropolitaine
    zones_metropolitaines = []
    for row in rows:
        cells = row.find_all('td')
        nom = cells[0].text.strip()
        population = int(cells[2].text.replace(',', ''))
        zones_metropolitaines.append({'nom': nom, 'population': population})

    # On trie les zones métropolitaines par taille de population
    zones_metropolitaines = sorted(zones_metropolitaines, key=lambda x: x['population'], reverse=True)

    # On garde les plus grandes zones métropolitaines
    zones_metropolitaines = zones_metropolitaines[:nb]

    # On calcule le logarithme de la taille et du rang de chaque zone métropolitaine
    zones_metropolitaines = [{'nom': zone['nom'], 'log_taille': np.log(zone['population']), 'log_rang': np.log(index + 1)} for index, zone in enumerate(zones_metropolitaines)]

    # On vérifie si les données suivent la loi de Zipf
    coefficient_zipf = np.polyfit([zone['log_rang'] for zone in zones_metropolitaines], [zone['log_taille'] for zone in zones_metropolitaines], 1)[0]
    print('Le coefficient de Zipf pour les', nb, f'premières villes des USA est : {coefficient_zipf:.3f}')
    
calcule_coefficient_zipf(135)
calcule_coefficient_zipf(235)
